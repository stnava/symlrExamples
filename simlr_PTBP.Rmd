---
title: 'The Pediatric Template of Brain Perfusion: SiMLR'
author: "Brian B. Avants et al."
date: "`r Sys.Date()`"
output: html_document
---

Similarity-driven multiview linear reconstruction can be used
in a manner similar to the SVD.  However, rather than running the
SVD independently on each modality, we run it jointly on all modalities.
This may provide a decomposition that reveals underlying structure in the
data that spans modalities.  In some cases, this latent space may provide
more powerful predictors for other outcomes that are reflected in
all of the measured modalities.  Furthermore, `simlr` predictors are sparse
and (optionally) constrained to be unsigned.  This may allow them to reveal
information that is more focal than the global view provided by SVD.

Here, we compare `simlr` to `svd` for predicting age and IQ in the pediatric
template of brain perfusion dataset.  The PTBP is freely available on Figshare.


## Load relevant packages

```{r setup,eval=TRUE,results='hide',warning=FALSE,echo=FALSE}
# set this for your own compilation
bd = path.expand( "~/capsule/data/" )
if ( ! dir.exists( bd ) ) bd = "./data/"
set.seed( 919 )
library( pander )
library( ggplot2 )
library( randomForestExplainer )
library(ANTsR)
library(visreg)
library(randomForest)
```

## Basic Setup

Get masks for each modality, along with matrices wherein the normalized
data is stored.

```{r dataio}
neanatvecs=2
thkmask=antsImageRead( paste(bd,"ptbp_mask_thickness.nii.gz",sep='') )
qth=0.05
mth='BH'
demog=read.csv(paste(bd,"ptbp_summary_demographics.csv",sep='') )
demog=demog[ , 1:19 ]
```

## Generic function to collect and organize data

```{r genericvox}
voxandeanatstudy <- function( demog, imgmat, imgmask,
                              formulabase, formulatest,
                              voi,
                              exclusionThresh,
                              baddata,
                              outprefix,
                              nv )
  {
  imgrowmeans=rowMeans( imgmat )
  wp = rep( FALSE, nrow( demog ) )
  for ( sub in unique( demog$SubID ) ) # get unique subjects
    {
    ww=which( demog$SubID == sub )
    ww=ww[ !is.na( imgrowmeans[ww] )  &
             imgrowmeans[ww] > exclusionThresh ]
    if ( length( ww ) > 0 ) wp[ ww[ 1 ] ] = TRUE
  }
 return( wp )
#  if ( ! all( is.na(baddata) ) ) # FIXME
#   wp[  which(wp==TRUE)[ baddata ] ]=FALSE # bad data
  ilist=matrixToImages( imgmat[wp,], imgmask )
#  for ( i in 1:length(ilist) ) ilist[[i]]=smoothImage( ilist[[i]], 2.0 )
  mydf=data.frame(
                 Sex=demog[wp,]$Sex,
                 AgeAtScan=demog[wp,]$AgeAtScan,
                 PIQ=demog[wp,]$Performance.IQ,
                 VIQ=demog[wp,]$Verbal.IQ,
                 BV=demog[wp,]$BV,
                 Cortex=demog[wp,]$Cortex,
                 LadderCom=demog[wp,]$Teen.Ladder.Community.Score,
                 LadderSES=demog[wp,]$Teen.Ladder.SES.score,
                 Income=demog[wp,]$Income )
  for ( kk in 2:ncol(mydf) ) mydf[,kk]=antsrimpute( mydf[,kk] )
  imgmat=imageListToMatrix( ilist, imgmask )
  locform=formula( paste( "imgmat ~", formulabase ,"+", formulatest ) )
  mdl=lm( locform, data=mydf )
  voxlm=bigLMStats( mdl , 1.e-8 )
  print(paste("begin low",outprefix) )
  lowmat = scale( lowrankRowMatrix( imgmat , 10 ), scale=FALSE )
  print(paste("begin eanat",outprefix) )
  imgeanat=sparseDecom( lowmat , imgmask, nvecs=nv, smooth=0.0,
    sparseness=0.05, cthresh=20000, mycoption=1, its=1 )
  rm( lowmat )
  print(paste("end eanat",outprefix) )
  eproj=abs(  imgeanat$eig  )
  eproj=( eproj/rowSums(eproj) )
  imgproj = imgmat %*% t( eproj  )
  mydf=data.frame( mydf, imgproj )
  print( names(mydf) )
  formbase=formula( paste( "imgproj ~", formulabase ) )
  formtest=formula( paste( "imgproj ~", formulabase ,"+", formulatest ) )
  mdl1=lm( formbase, data=mydf )
  mdl2=lm( formtest, data=mydf )
  eanatlm=bigLMStats( mdl2 , 1.e-6 )
  eseg=eigSeg( mask=imgmask, matrixToImages( imgeanat$eig, imgmask), F  )
  ofn=paste( outprefix, '_eseg.nii.gz', sep='' )
  antsImageWrite( eseg , ofn )
  anv=anova( mdl1, mdl2 )
  return( list(mydf=mydf,
               voxlm=voxlm,
               eanatlm=eanatlm,
               eseg=eseg,
               imgproj=imgproj,
               whichSubjects=wp,
               eanat=imgeanat,
               anv=anv) )
  }
```


# Three little modalities


## Cortical Thickness data

```{r thkfun}
############################################
thkmask=antsImageRead( paste(bd,"ptbp_mask_thickness.nii.gz",sep='') )
thkfn=paste(bd,"ptbp_vox_thk.mha",sep='')
thkmat=as.matrix( antsImageRead( thkfn ) )
thkmat[ is.na( thkmat ) ] = 0
baddata=NA
if ( ! exists("wthk")  ) {
  wthk=voxandeanatstudy( demog, thkmat, thkmask,
         formulathkbase, formulathktest, voi=voi,
         exclusionThresh = 0.5, baddata=baddata,
         outprefix='/tmp/Eanat_THK', nv=neanatvecs )
#  qv=p.adjust( ethk$eanatlm$beta.pval[ voi, ], method='BH' )
 # print( min(qv) )
  }
```

## Fractional anisotropy (FA) data

```{r fafun}
fafn=paste(bd,"ptbp_vox_fa.mha",sep='')
famask=antsImageRead( paste(bd,"ptbp_mask_fa.nii.gz",sep='') )
famat=as.matrix( antsImageRead( fafn ) )
famat[ is.na( famat ) ] = 0
baddata=c(42,44) # FA
if ( ! exists("wfa")  ) {
  wfa=voxandeanatstudy( demog, famat, famask,
         formulathkbase, formulathktest, voi=voi,
         exclusionThresh = 0.2, baddata=baddata,
         outprefix='/tmp/Eanat_FA', nv=neanatvecs )
 # qv=p.adjust( efa$eanatlm$beta.pval[ voi, ], method='BH' )
#  print( min(qv) )
  }
```

## Cerebral blood flow (CBF) data

```{r cbffun}
cbffn=paste(bd,"ptbp_vox_cbf.mha",sep='')
cbfmat=as.matrix( antsImageRead( cbffn ) )
cbfmat[ is.na( cbfmat ) ] = 0
baddata=NA
if ( ! exists("wcbf") ) {
  wcbf=voxandeanatstudy( demog, cbfmat, thkmask,
         formulathkbase, formulathktest, voi=voi,
         exclusionThresh = 45, baddata=baddata,
         outprefix='/tmp/Eanat_CBF', nv=neanatvecs )
#  qv=p.adjust( ecbf$eanatlm$beta.pval[ voi,], method='BH' )
 # print( min(qv) )
  }
```

# Three little modalities jointly

## SiMLR

```{r estimateRank}
if ( ! exists( "energyType" ) ) energyType = 'regression'
haveAllMerge=( wthk & wfa & wcbf )
inmats = list( thkmat[haveAllMerge,], famat[haveAllMerge,], cbfmat[haveAllMerge,] )
simlrRankEstimate <- function( targetVarx = 0.95, ... ) {
  # just run one permutation in order to get a baseline estimate
  j1 = scale( cbind( ... ), T, T )
  svd1 = svd( j1  )$d
  # how many do we need to explain XX% variance?
  varx = cumsum( svd1 ) / sum( svd1 )
  wv = min( which( varx >= targetVarx ) )
  j1p = scale( matrix( j1[ sample( prod( dim( j1 ) ) ) ], nrow=nrow(j1) ), T, T )
  svdperm = svd( j1p )$d
  varxp = cumsum( svdperm ) / sum( svdperm )
  myrankComp = svd1 > svdperm
  rm( j1, j1p )
  gc()
  return( list( svdD_original = svd1, svdD_perm = svdperm,
    varxComparison = myrankComp, suggestedRank = max( which(myrankComp[1:wv]) ) ) )
}
if ( ! exists( "rankData" ) )
  rankData = simlrRankEstimate( 0.90, inmats[[1]], inmats[[2]], inmats[[3]] )
```


```{r simlr}
if ( ! exists( "svdth" ) ) {
  svdth = svd(inmats[[1]],nu=rankData$suggestedRank,nv=0)$u
  svdcb = svd(inmats[[2]],nu=rankData$suggestedRank,nv=0)$u
  svdfa = svd(inmats[[3]],nu=rankData$suggestedRank,nv=0)$u
}
if ( ! exists( "smoms") ) { # regularization matrices
  smoms = list()
  spatmat = t( imageDomainToSpatialMatrix( thkmask, thkmask ) )
  smoms[[1]] = knnSmoothingMatrix( spatmat, k = 5^3, sigma = 20 )
  spatmat = t( imageDomainToSpatialMatrix( famask, famask ) )
  smoms[[2]] = knnSmoothingMatrix( spatmat, k = 5^3, sigma = 20 )
  smoms[[3]] = smoms[[1]]
}
targetRank = rankData$suggestedRank
# instead, for speed of example, reduce the value to K
targetRank = 4
initu = initializeSimlr( inmats, targetRank, jointReduction = T, uAlgorithm = 'ica' )
if ( ! exists( "mysym" ) ) {
  mysym = simlr(
      voxmats = inmats,
      smoothingMatrices = smoms,
      iterations = 50,
      sparsenessQuantiles = rep(0.9,3), # fewer voxels per component compared to default
      randomSeed = 98,
      initialUMatrix = initu,
      energyType = energyType,
      verbose = 1 )
  }
######
```

Predict SiMLR post-processing.

```{r predictSiMLR}
if ( ! exists( "pred2") ) {
  for ( k in 1:length( inmats ) ) {
    mysym$u[[k]] = inmats[[k]] %*% mysym$v[[k]]
    }
  pred = predictSimlr( inmats, mysym )
  # reorder simlr output
  for ( k in 1:length( mysym$v ) ) {
    mysym$v[[k]] = mysym$v[[k]][,pred$uOrder]
    mysym$u[[k]] = inmats[[k]] %*% mysym$v[[k]]
  }
  pred2 = predictSimlr( inmats, mysym )
}
pthk = inmats[[1]] %*% ( mysym$v[[1]] )
pfa = inmats[[2]] %*% ( mysym$v[[2]] )
pcbf = inmats[[3]] %*% ( mysym$v[[3]] )
nmm=c("thk","fa","pcbf")
```

Look at the `simlr` embeddings in comparison to SVD in terms of
overall regression fit to the data.

```{r brainAge}
ss=1:4
svdlr = svd( cbind(pthk,pfa,pcbf)  )$u
svdlr2 = svd( cbind(svdth,svdcb,svdfa)  )$u
simlrembeddings = cbind( pthk[,ss],  pcbf[,ss], pfa[,ss] )
m1 = lm( AgeAtScan ~   Sex, data = demog[haveAllMerge,] )
m2 = lm( AgeAtScan ~  simlrembeddings + Sex, data = demog[haveAllMerge,] )
m3 = lm( AgeAtScan ~ svdlr2[,1:ncol(simlrembeddings)] + Sex, data = demog[haveAllMerge,] )
print(mean(abs( demog[haveAllMerge,"AgeAtScan"] - predict(m2))))
print(mean(abs( demog[haveAllMerge,"AgeAtScan"] - predict(m3))))
```


```{r VIQ}
m1 = lm( Verbal.IQ ~   Sex + AgeAtScan , data = demog[haveAllMerge,] )
m2 = lm( Verbal.IQ ~  ( pthk[,ss] +  pfa[,ss]  +pcbf[,ss]) + Sex +  AgeAtScan , data = demog[haveAllMerge,] )
print( anova( m1, m2  ) )
```


```{r SES}
demog[haveAllMerge,"Income"] = antsrimpute(demog[haveAllMerge,"Income"])
m1 = lm( Teen.Ladder.SES.score ~   Sex + stats::poly(AgeAtScan,1), data = demog[haveAllMerge,] )
m2 = lm( Teen.Ladder.SES.score ~  ( pthk[,ss] + pfa[,ss]+ pcbf[,ss] ) + Sex + stats::poly(AgeAtScan,1)+1, data = demog[haveAllMerge,] )
# m2 = lm( Teen.Ladder.SES.score ~  ( svdth[,ss] + svdfa[,ss]+ svdcb[,ss] ) + Sex + AgeAtScan, data = demog[haveAllMerge,] )
print( anova( m1, m2  ) )
```

Compare `simlr` embeddings to SVD in terms of relationship with IQ.

```{r FIQ}
m1 = lm( FullScaleIQ ~   Sex + AgeAtScan, data = demog[haveAllMerge,] )
m2 = lm( FullScaleIQ ~  ( pthk[,ss] + pfa[,ss]+ pcbf[,ss] ) + Sex + AgeAtScan, data = demog[haveAllMerge,] )
print( anova( m1, m2  ) )
m3 = lm( FullScaleIQ ~  ( svdth[,ss] + svdcb[,ss]+ svdfa[,ss] ) + Sex + AgeAtScan, data = demog[haveAllMerge,] )
print( anova( m1, m3  ) )
# print( summary(m1) )
# print( summary(m2) )
```


```{r FIQp}
pander( m2 )
```


```{r sanitycheck}
print( summary(lm( pthk[,2] ~  ( pcbf[,2] + pfa[,2] ) + Sex + BV +
  AgeAtScan, data = demog[haveAllMerge,] )) )
# plot( thkmask, makeImage( thkmask,  abs(mysym$v[[1]][,1]) ) )
```


## Joint stats: Thickness, FA $+$ CBF

```{r jointstats,echo=FALSE}
alldf = data.frame( demog[haveAllMerge,], thk=pthk, fa=pfa, cbf=pcbf )
# alldf = data.frame( demog[haveAllMerge,], thk=svdth[,1:10], fa=svdfa[,1:10], cbf=svdcb[,1:10] )
alldf = alldf[,c(3,4,20:min(c(ncol(alldf),49) )) ]
mdl1=lm( AgeAtScan ~ . ,
  data=alldf[,c(1,2)])
mdl2=lm( AgeAtScan ~ . ,
  data=alldf[,])
knitr::kable(anova(mdl1,mdl2))
```


## Let's do some prediction

Use random forests to decide how relevant each
modality is to reproducible predictions of age.

First get the data organized.



## Build the RF model


```{r rfpred,echo=FALSE}
groups <- rep( c(1,2), 1000 )[1:nrow(alldf)]
traing=groups==1
testg=groups==2
mdl=randomForest(  AgeAtScan ~ . , data=alldf[traing,],localImp = TRUE )
predage = predict( mdl, newdata=alldf[ testg, ] )
print( paste( "Predicted age error:", mean( abs(predage - alldf[testg,]$AgeAtScan ) ) ) )
temp=data.frame(predage=predage,realage=alldf[testg,]$AgeAtScan )
vmdl=lm( predage~realage,data=temp)
visreg::visreg(vmdl)
```

## RF importance plot

```{r rfimp,echo=FALSE}
importance_frame <- measure_importance( mdl )
plot_multi_way_importance( importance_frame,  size_measure = "p_value" )
# impdf=data.frame(
#  predNames=colnames(alldf)[ rev(order(mdl$importance)) ],
#  importance=mdl$importance[ rev(order(mdl$importance)) ]
#  )
# knitr::kable(  impdf )
```




## Check the SiMLR regions of the brain

```{r thksimlr4,eval=TRUE,echo=FALSE}
fImgs = matrixToImages(t(mysym$v[[2]][,1:3]),famask)
cImgs = matrixToImages(t(mysym$v[[3]][,1:2]),thkmask)
tImgs = matrixToImages(t(mysym$v[[1]][,1:2]),thkmask)
template = antsImageRead( paste0(  bd, 'PTBP_T1_BrainCerebellum.nii.gz' ) )
plot( template, abs(tImgs[[1]])/max(abs(tImgs[[1]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
plot( template, abs(fImgs[[1]])/max(abs(fImgs[[1]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
plot( template, abs(cImgs[[1]])/max(abs(cImgs[[1]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
```

## Look over simlr results

Which demographic variables match which imaging variables?

```{r thksimlr2,eval=FALSE}
rownames( ssimlrn$eig2 )=colnames( sdemog )
knitr::kable( ssimlrn$eig2 )
```




# Review

## Discussion

* Reviewed sparse dimensionality reduction

* These methods update traditional dimensionality reduction tools for neuroimaging

* We showed strategies for using these modalities together to find meaningful predictors.

* Performed some visualization and interpretation.
