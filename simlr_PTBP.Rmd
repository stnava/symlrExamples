---
title: 'The Pediatric Template of Brain Perfusion: SiMLR'
author: "Brian B. Avants et al."
date: "`r Sys.Date()`"
output: html_document
---

Similarity-driven multiview linear reconstruction can be used
in a manner similar to the SVD.  However, rather than running the
SVD independently on each modality, we run it jointly on all modalities.
This may provide a decomposition that reveals underlying structure in the
data that spans modalities.  In some cases, this latent space may provide
more powerful predictors for other outcomes that are reflected in
all of the measured modalities.  Furthermore, `simlr` predictors are sparse
and (optionally) constrained to be unsigned.  This may allow them to reveal
information that is more focal than the global view provided by SVD.

Here, we compare `simlr` to `svd` for predicting age and IQ in the pediatric
template of brain perfusion dataset.  The PTBP is freely available on Figshare.


## Load relevant packages

```{r setup,eval=TRUE,results='hide',warning=FALSE,echo=FALSE}
# set this for your own compilation
bd = path.expand( "~/capsule/data/" )
if ( ! dir.exists( bd ) ) bd = "./data/"
set.seed( 919 )
library( pander )
library( ggplot2 )
library( randomForestExplainer )
library(ANTsR)
library(visreg)
library(randomForest)
if ( ! exists( "useRGCCA" ) ) useRGCCA = FALSE
```

## Basic Setup

Get masks for each modality, along with matrices wherein the normalized
data is stored.

```{r dataio}
neanatvecs=2
thkmask=antsImageRead( paste(bd,"ptbp_mask_thickness.nii.gz",sep='') )
qth=0.05
mth='BH'
demog=read.csv(paste(bd,"ptbp_summary_demographics.csv",sep='') )
demog=demog[ , 1:19 ]
```

## Generic function to collect and organize data

```{r genericvox}
voxandeanatstudy <- function( demog, imgmat, imgmask,
                              formulabase, formulatest,
                              voi,
                              exclusionThresh,
                              baddata,
                              outprefix,
                              nv )
  {
  imgrowmeans=rowMeans( imgmat )
  wp = rep( FALSE, nrow( demog ) )
  for ( sub in unique( demog$SubID ) ) # get unique subjects
    {
    ww=which( demog$SubID == sub )
    ww=ww[ !is.na( imgrowmeans[ww] )  &
             imgrowmeans[ww] > exclusionThresh ]
    if ( length( ww ) > 0 ) wp[ ww[ 1 ] ] = TRUE
  }
 return( wp )
#  if ( ! all( is.na(baddata) ) ) # FIXME
#   wp[  which(wp==TRUE)[ baddata ] ]=FALSE # bad data
  ilist=matrixToImages( imgmat[wp,], imgmask )
#  for ( i in 1:length(ilist) ) ilist[[i]]=smoothImage( ilist[[i]], 2.0 )
  mydf=data.frame(
                 Sex=demog[wp,]$Sex,
                 AgeAtScan=demog[wp,]$AgeAtScan,
                 PIQ=demog[wp,]$Performance.IQ,
                 VIQ=demog[wp,]$Verbal.IQ,
                 BV=demog[wp,]$BV,
                 Cortex=demog[wp,]$Cortex,
                 LadderCom=demog[wp,]$Teen.Ladder.Community.Score,
                 LadderSES=demog[wp,]$Teen.Ladder.SES.score,
                 Income=demog[wp,]$Income )
  for ( kk in 2:ncol(mydf) ) mydf[,kk]=antsrimpute( mydf[,kk] )
  imgmat=imageListToMatrix( ilist, imgmask )
  locform=formula( paste( "imgmat ~", formulabase ,"+", formulatest ) )
  mdl=lm( locform, data=mydf )
  voxlm=bigLMStats( mdl , 1.e-8 )
  print(paste("begin low",outprefix) )
  lowmat = scale( lowrankRowMatrix( imgmat , 10 ), scale=FALSE )
  print(paste("begin eanat",outprefix) )
  imgeanat=sparseDecom( lowmat , imgmask, nvecs=nv, smooth=0.0,
    sparseness=0.05, cthresh=20000, mycoption=1, its=1 )
  rm( lowmat )
  print(paste("end eanat",outprefix) )
  eproj=abs(  imgeanat$eig  )
  eproj=( eproj/rowSums(eproj) )
  imgproj = imgmat %*% t( eproj  )
  mydf=data.frame( mydf, imgproj )
  print( names(mydf) )
  formbase=formula( paste( "imgproj ~", formulabase ) )
  formtest=formula( paste( "imgproj ~", formulabase ,"+", formulatest ) )
  mdl1=lm( formbase, data=mydf )
  mdl2=lm( formtest, data=mydf )
  eanatlm=bigLMStats( mdl2 , 1.e-6 )
  eseg=eigSeg( mask=imgmask, matrixToImages( imgeanat$eig, imgmask), F  )
  ofn=paste( outprefix, '_eseg.nii.gz', sep='' )
  antsImageWrite( eseg , ofn )
  anv=anova( mdl1, mdl2 )
  return( list(mydf=mydf,
               voxlm=voxlm,
               eanatlm=eanatlm,
               eseg=eseg,
               imgproj=imgproj,
               whichSubjects=wp,
               eanat=imgeanat,
               anv=anv) )
  }
```


# Collect each of the voxel-wise matrix modalities


## Cortical Thickness data

The thickness of the cortex is a well-known maturational index with
rapid changes during adolescence.  Here, we use DiReCT in ANTs to estimate
thickness from T1 data and stored the result, after normalization to a group
template, in a matrix.  The PTBP paper describes this in more detail.
The mask covers template cortex.

```{r thkfun}
############################################
thkmask=antsImageRead( paste(bd,"ptbp_mask_thickness.nii.gz",sep='') )
thkfn=paste(bd,"ptbp_vox_thk.mha",sep='')
thkmat=as.matrix( antsImageRead( thkfn ) )
thkmat[ is.na( thkmat ) ] = 0
baddata=NA
if ( ! exists("wthk")  ) {
  wthk=voxandeanatstudy( demog, thkmat, thkmask,
         formulathkbase, formulathktest, voi=voi,
         exclusionThresh = 0.5, baddata=baddata,
         outprefix='/tmp/Eanat_THK', nv=neanatvecs )
#  qv=p.adjust( ethk$eanatlm$beta.pval[ voi, ], method='BH' )
 # print( min(qv) )
  }
```

## Fractional anisotropy (FA) data

FA is a maturational index that relates to the connective structure in the
brain and is complementary to cortical thickness (computation vs wiring).
As with CT, the FA is normalizes to a template and collected into a matrix
here.  The mask covers template white matter.

```{r fafun}
fafn=paste(bd,"ptbp_vox_fa.mha",sep='')
famask=antsImageRead( paste(bd,"ptbp_mask_fa.nii.gz",sep='') )
famat=as.matrix( antsImageRead( fafn ) )
famat[ is.na( famat ) ] = 0
baddata=c(42,44) # FA
if ( ! exists("wfa")  ) {
  wfa=voxandeanatstudy( demog, famat, famask,
         formulathkbase, formulathktest, voi=voi,
         exclusionThresh = 0.2, baddata=baddata,
         outprefix='/tmp/Eanat_FA', nv=neanatvecs )
 # qv=p.adjust( efa$eanatlm$beta.pval[ voi, ], method='BH' )
#  print( min(qv) )
  }
```

## Cerebral blood flow (CBF) data

In contrast to the prior two measurements, CBF is a functional measurement
related to blood flow or perfusion in the brain.  CBF is more variable
during the day and with a variety of other factors in comparison to structural
measurements.  However, it also shows general trends that relate to maturation.
The matrix, here, covers the cortex.

```{r cbffun}
cbffn=paste(bd,"ptbp_vox_cbf.mha",sep='')
cbfmat=as.matrix( antsImageRead( cbffn ) )
cbfmat[ is.na( cbfmat ) ] = 0
baddata=NA
if ( ! exists("wcbf") ) {
  wcbf=voxandeanatstudy( demog, cbfmat, thkmask,
         formulathkbase, formulathktest, voi=voi,
         exclusionThresh = 45, baddata=baddata,
         outprefix='/tmp/Eanat_CBF', nv=neanatvecs )
#  qv=p.adjust( ecbf$eanatlm$beta.pval[ voi,], method='BH' )
 # print( min(qv) )
  }
```

# Joint modeling of thickness, FA and CBF

## SiMLR

We first collect only subjects that have all 3 modalities.  We then demonstrate
one approach to auto-select the rank for the call to `simlr`.  The example
disregards the recommended rank for expediency and because we are primarily
interested in testing the largest components of covariation.

```{r estimateRank}
if ( ! exists( "energyType" ) ) energyType = 'regression'
haveAllMerge=( wthk & wfa & wcbf )
inmats = list( thkmat[haveAllMerge,], famat[haveAllMerge,], cbfmat[haveAllMerge,] )
simlrRankEstimate <- function( targetVarx = 0.95, ... ) {
  # just run one permutation in order to get a baseline estimate
  j1 = scale( cbind( ... ), T, T )
  svd1 = svd( j1  )$d
  # how many do we need to explain XX% variance?
  varx = cumsum( svd1 ) / sum( svd1 )
  wv = min( which( varx >= targetVarx ) )
  j1p = scale( matrix( j1[ sample( prod( dim( j1 ) ) ) ], nrow=nrow(j1) ), T, T )
  svdperm = svd( j1p )$d
  varxp = cumsum( svdperm ) / sum( svdperm )
  myrankComp = svd1 > svdperm
  rm( j1, j1p )
  gc()
  return( list( svdD_original = svd1, svdD_perm = svdperm,
    varxComparison = myrankComp, suggestedRank = max( which(myrankComp[1:wv]) ) ) )
}
if ( ! exists( "rankData" ) )
  rankData = simlrRankEstimate( 0.90, inmats[[1]], inmats[[2]], inmats[[3]] )
```

In this code chunk, we precompute SVD on each matrix, prepare regularization
matrices (using wrapper functions from ANTsR) and then call SiMLR with
sparseness parameters set somewhat higher than defaults to yield more focal
feature vectors.

```{r simlr}
if ( ! exists( "svdth" ) ) {
  svdth = svd(inmats[[1]],nu=rankData$suggestedRank,nv=0)$u
  svdcb = svd(inmats[[2]],nu=rankData$suggestedRank,nv=0)$u
  svdfa = svd(inmats[[3]],nu=rankData$suggestedRank,nv=0)$u
}
if ( ! exists( "smoms") ) { # regularization matrices based on spatial proximity
  smoms = list()
  spatmat = t( imageDomainToSpatialMatrix( thkmask, thkmask ) )
  smoms[[1]] = knnSmoothingMatrix( spatmat, k = 5^3, sigma = 20 )
  spatmat = t( imageDomainToSpatialMatrix( famask, famask ) )
  smoms[[2]] = knnSmoothingMatrix( spatmat, k = 5^3, sigma = 20 )
  smoms[[3]] = smoms[[1]]
}
targetRank = rankData$suggestedRank
# instead, for speed of example, reduce the value to K
targetRank = 4
mixAlg = 'ica'
initu = initializeSimlr( inmats, targetRank, jointReduction = T, uAlgorithm = mixAlg )

if ( useRGCCA ) {
  if ( ! exists( "myrgcca" ) ) {
    library( RGCCA )
    # tau parameters below correspond to inter-battery factor analysis settings
    # https://cran.r-project.org/web/packages/RGCCA/vignettes/vignette_RGCCA.pdf
    myrgcca = sgcca( # this initializes with SVD
      A = inmats,
      C = 1 - diag( 3 ), # cca-like
      c1 = 0.2,  # set to roughly match simlr
      # tau = c( 1, 1 ), # for rgcca only
      ncomp = c( targetRank, targetRank, targetRank ), scale = TRUE, verbose = TRUE )
    mysym = list( v=myrgcca$a )
    pred2 = NULL
  }
}

if ( ! exists( "mysym" ) ) {
  mysym = simlr(
      voxmats = inmats,
      smoothingMatrices = smoms,
      iterations = 50,
      sparsenessQuantiles = rep(0.9,3), # fewer voxels per component compared to default
      randomSeed = 98,
      initialUMatrix = initu,
      energyType = energyType,
      mixAlg = mixAlg,
      verbose = 1 )
  }
######
```

Predict SiMLR post-processing. This helper function provides a variety
of user-controllable outputs that can help one determine how one may want to
reorder SiMLR components e.g. by their explanatory power either within or across
modalities.  Lastly, in this section, we compute the projections of the feature
vectors onto the original matrices (the components or embeddings).

```{r predictSiMLR}
if ( ! exists( "pred2") ) {
  for ( k in 1:length( inmats ) ) {
    mysym$u[[k]] = inmats[[k]] %*% mysym$v[[k]]
    }
  pred = predictSimlr( inmats, mysym )
  # reorder simlr output
  for ( k in 1:length( mysym$v ) ) {
    mysym$v[[k]] = mysym$v[[k]][,pred$uOrder]
    mysym$u[[k]] = inmats[[k]] %*% mysym$v[[k]]
  }
  pred2 = predictSimlr( inmats, mysym )
}
pthk = inmats[[1]] %*% ( mysym$v[[1]] )
pfa = inmats[[2]] %*% ( mysym$v[[2]] )
pcbf = inmats[[3]] %*% ( mysym$v[[3]] )
nmm=c("thk","fa","pcbf")
```

Look at the `simlr` embeddings in comparison to SVD in terms of
overall regression fit to the data using only the top 4 predictors.

```{r brainAge}
ss=1:4
simlrembeddings = cbind( pthk[,ss],  pcbf[,ss], pfa[,ss] )  # joined simlr vectors
svdlr = svd( cbind(pthk,pfa,pcbf)  )$u        # SVD of the joined simlr vectors
svdlr2 = svd( cbind(svdth,svdcb,svdfa)  )$u   # SVD of the joined SVD vectors
m1 = lm( AgeAtScan ~   Sex, data = demog[haveAllMerge,] ) # base model
m2 = lm( AgeAtScan ~  simlrembeddings + Sex,
  data = demog[haveAllMerge,] ) # simlr model
m3 = lm( AgeAtScan ~ svdlr2[,1:ncol(simlrembeddings)] + Sex,
  data = demog[haveAllMerge,] ) # svd model
print(mean(abs( demog[haveAllMerge,"AgeAtScan"] - predict(m2))))
print(mean(abs( demog[haveAllMerge,"AgeAtScan"] - predict(m3))))
```

Do these embeddings relate to verbal IQ?

```{r VIQ}
m1 = lm( Verbal.IQ ~   Sex + AgeAtScan , data = demog[haveAllMerge,] ) # base
m2 = lm( Verbal.IQ ~  ( pthk[,ss] +  pfa[,ss]  +pcbf[,ss]) + Sex +  AgeAtScan,
  data = demog[haveAllMerge,] ) # simlr VIQ
print( anova( m1, m2  ) )
```

Do these embeddings relate to SES?

```{r SES}
demog[haveAllMerge,"Income"] = antsrimpute(demog[haveAllMerge,"Income"])
m1 = lm( Teen.Ladder.SES.score ~   Sex + stats::poly(AgeAtScan,1),
  data = demog[haveAllMerge,] ) # base
m2 = lm( Teen.Ladder.SES.score ~  ( pthk[,ss] + pfa[,ss]+ pcbf[,ss] ) +
  Sex + stats::poly(AgeAtScan,1)+1, data = demog[haveAllMerge,] ) # simlr
print( anova( m1, m2  ) )
```

Compare `simlr` embeddings to SVD in terms of relationship with total IQ.

```{r FIQ}
m1 = lm( FullScaleIQ ~   Sex + AgeAtScan, data = demog[haveAllMerge,] ) # base
m2 = lm( FullScaleIQ ~  ( pthk[,ss] + pfa[,ss]+ pcbf[,ss] ) + Sex +
  AgeAtScan, data = demog[haveAllMerge,] ) # simlr
print( anova( m1, m2  ) )
m3 = lm( FullScaleIQ ~  ( svdth[,ss] + svdcb[,ss]+ svdfa[,ss] ) + Sex +
  AgeAtScan, data = demog[haveAllMerge,] ) # svd, same size model
print( anova( m1, m3  ) )
```

Show the model Coefficients.

```{r FIQp}
pander( m2 )
```

Perform a sanity check that there should also be a relationship between
the embeddings.

```{r sanitycheck}
print( summary(lm( pthk[,2] ~  ( pcbf[,2] + pfa[,2] ) + Sex + BV +
  AgeAtScan, data = demog[haveAllMerge,] )) )
```



# Joint modeling: Thickness, FA $+$ CBF predicting age


First, organize the data that we need into a single data frame
and define train/test groups.
We will evaluate - using a 50/50 data split - the age prediction error based on
these 3 modalities.

```{r jointstats,echo=FALSE}
alldf = data.frame( demog[haveAllMerge,], thk=pthk, fa=pfa, cbf=pcbf )
alldf = alldf[,c(3,4,20:min(c(ncol(alldf),49) )) ]
groups <- rep( c(1,2), 1000 )[1:nrow(alldf)] # 50-50 split
traing=groups==1
testg=groups==2
```


## Let's do some prediction

Use random forests to decide how relevant each
modality and embedding is to predictions of age.

Also report the mean absolute error in age prediction as is standard in brain age.
The values below are in years.  Generally, for this narrow age range, one to two
years error is expected.  Our prior PTBP and eigenanatomy
publications provide some guidance on this.

First get the data organized.

## Build the RF model

In general, one should run several iterations of the below calculations in order
to better understand the distribution of results.  However, this gives the
basic idea.

```{r rfpred,echo=FALSE}
mdl=randomForest(  AgeAtScan ~ . , data=alldf[traing,],localImp = TRUE )
predage = predict( mdl, newdata=alldf[ testg, ] )
print( paste( "Predicted age error:", mean( abs(predage - alldf[testg,]$AgeAtScan ) ) ) )
temp=data.frame(predage=predage,realage=alldf[testg,]$AgeAtScan )
vmdl=lm( predage~realage,data=temp)
visreg::visreg(vmdl)
```

## RF importance plot

The random forest importance plot sheds light on which variables are most
relevant in the RF decision tree.

```{r rfimp,echo=FALSE}
importance_frame <- measure_importance( mdl )
plot_multi_way_importance( importance_frame,  size_measure = "p_value" )
# impdf=data.frame(
#  predNames=colnames(alldf)[ rev(order(mdl$importance)) ],
#  importance=mdl$importance[ rev(order(mdl$importance)) ]
#  )
# knitr::kable(  impdf )
```




## Check the SiMLR regions of the brain

Lastly, we visualize the feature vectors. First, thickness (top two).

```{r thksimlr4,eval=TRUE,echo=FALSE}
template = antsImageRead( paste0(  bd, 'PTBP_T1_BrainCerebellum.nii.gz' ) )
tImgs = matrixToImages(t(mysym$v[[1]][,1:4]),thkmask)
if ( !useRGCCA ) {
  plot( template, abs(tImgs[[1]])/max(abs(tImgs[[1]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
  plot( template, abs(tImgs[[2]])/max(abs(tImgs[[2]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
}
if ( useRGCCA ) {
  k = 4
  temp1 = tImgs[[k]] * thresholdImage( tImgs[[k]], 1e-6, Inf )
  temp2 = ( tImgs[[k]] * (-1.0) ) * thresholdImage( ( tImgs[[k]] * (-1.0) ), 1e-6, Inf )
  layout( matrix( 1:2,nrow=1))
  plot( template, temp1/max(abs(temp1)), window.overlay=c(0.1,1), axis=3, nslices=16 )
  plot( template, temp2/max(abs(temp2)), window.overlay=c(0.1,1), axis=3, nslices=16 )
}
```

Fractional anisotropy features.

```{r FAsimlr4,eval=TRUE,echo=FALSE}
fImgs = matrixToImages(t(mysym$v[[2]][,1:3]),famask)
plot( template, abs(fImgs[[1]])/max(abs(fImgs[[1]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
plot( template, abs(fImgs[[2]])/max(abs(fImgs[[2]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
```

CBF features.

```{r CBFsimlr4,eval=TRUE,echo=FALSE}
cImgs = matrixToImages(t(mysym$v[[3]][,1:2]),thkmask)
plot( template, abs(cImgs[[1]])/max(abs(cImgs[[1]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
plot( template, abs(cImgs[[2]])/max(abs(cImgs[[2]])), window.overlay=c(0.1,1), axis=3, nslices=16 )
```


# Discussion

* Reviewed how to set up simlr for imaging studies including regularization
and parameter setting.

* Compared these methods to traditional dimensionality reduction tools for neuroimaging

* We showed strategies for using these modalities together to find meaningful predictors.

* Performed some visualization and interpretation.
